{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Functions, String and Array Manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will be exploring how to manipulate, slice, and work with data stored in arrays, lists, and strings, through the use of functions. We'll be applying these techniques to astronomical specrta (discussed below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RUN THIS CELL BLOCK!!!!!\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyfits as pf\n",
    "%matplotlib inline\n",
    "!pip install -U okpy \n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw2.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astronomical Spectra: Slicing Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astronomers basically have one way of learning about the universe: **detecting photons**. Pretty much everything we know in astrophysics comes from the analysis of data which is nothing more than how many photons we received from a certain location in the sky. Many of us grew up seeing images, of astrophysical objects like galaxies taken by the Hubble Space Telescope (HST). Those images are useful, and drawing information out of how many photons are in a given pixel bin is what's known as **photometry**. However, there is another really important way of learning about astrophysical objects via their photons. Astronomers take **spectra** of objects to determine everything from their elemental composition to their radial velocity to the amount of dust or obscured star formation going on, etc.\n",
    "\n",
    "A spectrum is basically what you see when you use a prism to spread out white light into a rainbow. Advanced spectrometers use what is known as an echelle grating to split up light and 'bin' it by wavelength, allowing us to see at every wavelength how many photons we receive from a given source. Almost no astrophysical source in the universe emits a flat (equal strength at all wavelengths) spectrum.\n",
    "\n",
    "In the cell below, we load a **FITS** file (we'll get to those later) containing a solar spectrum, which ends up displaying the plot below. Let's see how we can slice and dice this image to get out a 1 dimensional spectrum!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fits_file = pf.open('solar_spec.fits')[0] #use the pyfits library to load the file\n",
    "image = fits_file.data #extract the 2D CCD Image of the spectra\n",
    "plt.imshow(image,cmap='gray_r') #Display the raw image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1a**\n",
    "\n",
    "What we see above doesn't really look like much of anything, yet. We are actually looking at exactly what our 2-dimensional CCD chip (like the ones in your phone, but fancier) picked up. Our spectograph did something funny, for reasons you'll learn in Astro 120, and split the light into these black horizontal bands we see (Note: the cmap='gray_r' command reversed the image such that dark represents areas of high light flux and white represents low flux. So the light is in the thin black bands, not the white spaces between them). Believe it or not, the spectra are actually hiding in those bands. We need to figure out how to extract just one of those bands to look at (at least at one time). \n",
    "\n",
    "To get an idea of how wide the individual bands are (from now on we'll call them \"orders\"), set a variable called ```vertical_profile``` equal to all the values forming the 500th (center) column (by index) of the image. What do you expect this to look like? try plotting the values you just extracted by typing ```plt.plot(vertical_profile)``` followed by ```plt.show()``` \n",
    "under your variable declaration in the box below, and then run it to see.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q01a')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was this what you expected to see? What we should be seeing here is the brightness of the image as a function of vertical position, for a single column. Everywhere there's a black stripe corresponding to an order of light, we see a spike in the number of photons the detector picks up. We can even note how the spikes get progressively higher towards the right of our plot, just as the bars get thicker and darker towards the bottom of the image we plotted above. \n",
    "\n",
    "This was helpful, but we really want to zoom in and figure out the edges of a single order. Let's go with the spike that looks like it's at around 700 on the plot you (hopefully) made. Make a variable called ```smaller_slice``` below and set it to index your ```vertical_profile``` array from around 690 to 710, to catch the peak I just mentioned. Plot it as well, to see that you're catching one full peak, and not too much noise around it (though in a second that noise isn't really gonna matter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Hopefully, that worked! If you look closely, you'll notice that every time we've sliced into and extracted entries from an array, they get re-indexed from 0 every time. Your plot above should go from 0 to 19 on the x-axis, for example. If we wanted to know what index 10 here corresponded to in the plot of ```vertical_profile``` above, we'd want to take our start index of the slice, 690, and add 10. \n",
    "\n",
    "**Question 1b**\n",
    "\n",
    "We don't have to worry about that problem when using indices from ```vertical_profile``` to index ```image``` because we took the whole column, not a subset, so any indices in ```vertical_profile``` are the same in the image.\n",
    "\n",
    "That said, it's time to finally extract the solar spectrum! Looking at the plot of ```smaller_slice``` we can see that the row 690 plus ~ 11 of the image will definitely be a solid line of pixels to choose, and will definitely contain the solar data we are after. \n",
    "\n",
    "Set a variable ```row_slice``` to the 701st (by index) row of the original image, and plot the result below. If you forgot how to index for multiple rows or columns at once, check out the textbook ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q01b')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You've just extracted your first spectrum! Well, technically, what we are looking at isn't a spectrum because we are viewing the number of photons (or flux) as a function of pixel number on the CCD, not wavelength, We'd have to go through some conversions to get all the way there, but the basic principles are all here. \n",
    "\n",
    "Ultimately, loading a single row of pixels like we've done here can be pretty dangerous, especially when we have more than one row of pixels per order with good data in it (and the more we use, the smaller our uncertainties). In fact, if you look at the plot of your spectrum you'll see it tapers off rather steeply on the right hand side. If you go back to the image of the CCD, you'll see that many of the orders are tilted, and get weaker from one side to the other. By taking a single row, we open ourselves up to those things really affecting our results. So, we've provided one step toward a better option- what if we choose a \"box\" around the order we are after, and take the vertical average within that box for every column? The result of that idea is set up for you in the box below. Run it, and see if you can figure out the syntax being used to accomplish it. Can you think of any other ideas for improving on our extraction of these spectra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flattened_spectrum = image[695:708,:].mean(axis=0)\n",
    "plt.plot(flattened_spectrum)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1c**\n",
    "\n",
    "Now that we have a spectrum to work with, we can start performing some of the corrections and adjustments we would make before displaying it in a paper or performing analysis. \n",
    "\n",
    "The first thing we notice about the flattened spectrum above is that there's this weird, precipitous drop near the end. That's not real; the drop in intensity is due internal optics within the system. Essentially, this order receives no light in its last several pixels. Since they aren't data, and are making it hard to see what is happening in the spectrum, let's remove them. \n",
    "\n",
    "I've done some tinkering, and it seems like the last 20 pixels should be dropped from the spectrum. Set ```flattened_spectrum``` below to be itself, but indexed to not include the last 20 values (negative indices might be helpful here!). Then replot it to see what it looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q01c')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see here are two components of the spectrum: a continuum component, and the spectral lines. The continuum is the broad \"bump\" shape of the spectrum, the shape it would be if the individual dips weren't there. Those dips are known as **absorption features** or **absorption lines** and are the part of the spectrum that contain information about the chemical elements in the plasma at the surface of the sun, as well as the doppler shifts that may be associated with the gas (whether it is moving towards or away from us). So we want to actually subtract off the continuum emmission (the broad shape) and get a flat spectrum. This is a little tricky, so we'll do this step for you, but try to follow what we are doing in the comments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Start by fitting a third degree polynomial to the spectrum as a rough estimate for the shape of the curve (usually this is sufficient)\n",
    "x = np.arange(len(flattened_spectrum)) #plotting without x basically just creates this for you\n",
    "fit = np.polyfit(x,flattened_spectrum,3) #specify third order fit (we will go over fits in 2 weeks)\n",
    "a = fit[0] #extract the coefficients\n",
    "b = fit[1] #extract the coefficients\n",
    "c = fit[2] #extract the coefficients\n",
    "d = fit[3] #extract the coefficients\n",
    "\n",
    "y_fit = a*x**3 + b*x**2 + c*x + d #set up a y array with the polynomial equation\n",
    "\n",
    "plt.plot(x,flattened_spectrum,label='Raw Spectrum')\n",
    "plt.plot(x,y_fit,'r',lw=2,label='Cubic Polynomial Fit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the polynomial does a decent job fitting the continuum, though it slightly underpredicted the continuum level, so I added in an extra constant offset (the plus 300) to get it closer. In reality we'd have to tinker a bit more, but for our purposes here this is fine.\n",
    "\n",
    "**Question 1d**\n",
    "\n",
    "Now that we have a reasonable fit to the data we want to subtract off the predicted continuum at every pixel value from our flattened spectrum. Since everything is in numpy arrays, this is super easy. \n",
    "\n",
    "In the code block below, set a variable ```continuum_subtracted_spectrum``` to be the flattened spectrum with the fit continuum value for each pixel (stored in ```y_fit```) subtracted off, and then plot it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q01d')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be able to see from the small \"wavy\" pattern here that we didn't do a perfect job zeroing out the continuum emission, but that's alright. We now have what any astronomer would instantly recognize as a line spectrum of an astrophysical source. We could now start doing science, like calculating line widths and depths, and figuring out what elements we have in this gas and whether or not it is doppler shifted! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far in this class, we have been defining variables and either plotting them or printing them to learn something about their values. However, writing your own functions makes your code shorter, easier to debug (more on that in a bit), and easier to follow. In practice, almost any task you are going to perform more than once on different variables deserves a function; it really will make things easier. \n",
    "\n",
    "Lets look at an example. Say I had just read in a catalog of exoplanets discovered by the Kepler mission. Upon extracting the \"ID/Name\" column of the data to try to get the name for each exoplanet, I discover that they list the name in the form of a string that looks like this: '20160207KOI3715b_obs17-18-19'. That is a bit unweildy, even though all the information within that string is probably useful to us in some way or another, such as the date of observation (02/07/2016) and observation numbers (17,18,19). But we are only interested in the name right now, for our current project- so we want to extract the 'KOI3715b' part of the string and nothing else. \n",
    "\n",
    "Well, looking at the string we extracted, we might be tempted to just write something like ```name_extracted=nameidstr[8:16]```, remembering that when indexing, it includes the start index and stops one before the end index. But this is dangerous for several reasons. First, I have like, five-hundred or a thousand or maybe even more names to extract. Doing them all one by one wouldn't make much sense. Moreover, there's no inherent guarantee that the strings are all alike, that is, that the index the name starts on and ends on is the same in every string. There must be **some** convention- the data is **designed** to be parsed. So I'm gonna write a function to do it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOI3715b\n"
     ]
    }
   ],
   "source": [
    "def find(string, char): # Don't worry about while and ifs here, we will get to those. This simply finds a character\n",
    "    index = 0           # in a string and returns its index within the string \n",
    "    while index < len(string):\n",
    "        if string[index] == char:\n",
    "            return index\n",
    "        index += 1\n",
    "    return -1\n",
    "\n",
    "def extract_name(string):\n",
    "    start_index = find(string,'K')\n",
    "    end_index = find(string,'_')\n",
    "    extracted = string[start_index:end_index]\n",
    "    return extracted\n",
    "\n",
    "\n",
    "name1 = '20160207KOI3715b_obs17-18-19'\n",
    "short_name1 = extract_name(name1)\n",
    "print(short_name1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is a great example of how we can not only write functions to accomplish tasks, but we can call functions from other functions (notice how I used my find function within my extract name function) and even have functions inside functions if we want. All of this helps modularlize our code into more managable pieces, and makes our code more general- a well written function can be applied to all sorts of information- it's just a pipeline for turning inputs to outputs. Let's get a little bit of practice writing some functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Write a function called string_explosion that takes in a non-empty string like \"Code\" and returns a long string containing every prefix of the input. That is, building the word using the first character, then the first two characters, then the first three, etc. For example:\n",
    "\n",
    "in: string_splosion('Code')\n",
    "\n",
    "out: 'CCoCodCode'\n",
    "\n",
    "in: string_splosion('data!')\n",
    "\n",
    "out: 'ddadatdatadata!'\n",
    "\n",
    "in: string_splosion('hi')\n",
    "\n",
    "out: 'hhi'\n",
    "\n",
    "(adapted from DS100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q02')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Finish the function below which solves the quadratic equation (the dreadful thing we all learned in high school, now barely use, but groan really loudly if we have to). In case you need a reminder, the formula is \n",
    "$$x =\\frac{ -b \\pm \\sqrt{b^2 + 4ac}}{2a} $$\n",
    "\n",
    "We've set up the structure of the function for you, with some documentation (in the quotes) which, if someone ran a help function on your function would pull up that documentation. In that documentation you'll notice it specifies what happens if the discriminant is negative. numpy's sqrt function doesn't like negatives, and won't just spit out a nice 'i' for you. If someone were running many calculations, they'd want to know when something didn't have real roots, so we've put in an error message for that case. Your code should be where the ellipses are, for the case when the descriminant is >=0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quad_solve(a,b,c):\n",
    "    '''\n",
    "    A function to solve the quadratic formula for any a,b,c.\n",
    "    Parameters\n",
    "    --------------\n",
    "    a (float): quadratic coefficient \n",
    "    b (float): linear coefficient\n",
    "    c (float): constant coefficient\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    x1 (positive case), x2 (negative case) (float): The solution to the quadratic fomula, both values of x should both exist, or 1 if only one exists\n",
    "    OR\n",
    "    x (float): if only one intercept exists\n",
    "    Exceptions\n",
    "    -------------\n",
    "    If the discriminant is < 0 (no real roots), None is returned. \n",
    "    ''' \n",
    "    discriminant = b**2 + 4*a*c\n",
    "    if discriminant < 0:\n",
    "        # Discriminant was not positive, returning None \n",
    "        return None\n",
    "    elif discriminant==0:\n",
    "        ...\n",
    "        return x\n",
    "    else:\n",
    "        ...\n",
    "        ...\n",
    "        return x1, x2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q03')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You are done with the tutorial! Follow the cells below to submit your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = ok.grade_all() #Grade all the tests to make sure you haven't missed anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, we'll submit to okpy\n",
    "_ = ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
